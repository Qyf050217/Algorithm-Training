import os
import csv
import re
from datetime import datetime
from collections import defaultdict

# --- 1. è·¯å¾„è‡ªåŠ¨å®šä½ ---
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))

ACCEPTED_DIR = os.path.join(BASE_DIR, 'Accepted')
ATTEMPTED_DIR = os.path.join(BASE_DIR, 'Attempted')
HISTORY_CSV = os.path.join(BASE_DIR, 'training_history.csv')
README_FILE = os.path.join(BASE_DIR, 'README.md')

# --- 2. é…ç½®å‚æ•° ---
TOP_N = 5

def get_oj_url(cpp_path):
    """ä»åŒç›®å½•ä¸‹çš„ .cph æ–‡ä»¶å¤¹æå–ç½‘å€"""
    cpp_filename = os.path.basename(cpp_path)
    cph_dir = os.path.join(os.path.dirname(cpp_path), '.cph')
    if os.path.exists(cph_dir) and os.path.isdir(cph_dir):
        for f in os.listdir(cph_dir):
            if f.endswith('.prob') and cpp_filename in f:
                try:
                    with open(os.path.join(cph_dir, f), 'r', encoding='utf-8') as f_in:
                        content = f_in.read()
                        url = re.search(r'https?://[^\s"\'\}]+', content)
                        if url: return url.group(0)
                except: continue
    return None

def persist_to_csv(daily_ac, platforms):
    """å°†ç»Ÿè®¡æ•°æ®æŒä¹…åŒ–åˆ° CSV ä¾› heatmap.py ç»˜å›¾"""
    headers = ['Date'] + platforms + ['Total']
    rows = []
    for d in sorted(daily_ac.keys()):
        row = {'Date': d}
        total = 0
        for p in platforms:
            val = daily_ac[d].get(p, 0)
            row[p] = val
            total += val
        row['Total'] = total
        rows.append(row)

    with open(HISTORY_CSV, 'w', newline='', encoding='utf-8-sig') as f:
        writer = csv.DictWriter(f, fieldnames=headers)
        writer.writeheader()
        writer.writerows(rows)

def get_stats():
    daily_ac = defaultdict(lambda: defaultdict(int))
    all_platforms = set()
    if os.path.exists(ACCEPTED_DIR):
        for p in os.listdir(ACCEPTED_DIR):
            p_path = os.path.join(ACCEPTED_DIR, p)
            if os.path.isdir(p_path):
                all_platforms.add(p)
                for d in os.listdir(p_path):
                    d_path = os.path.join(p_path, d)
                    if os.path.isdir(d_path):
                        count = len([f for f in os.listdir(d_path) if f.endswith('.cpp')])
                        daily_ac[d][p] += count
    return daily_ac, sorted(list(all_platforms))

def get_top_n(folder, reverse_sort=True):
    """æ‰«æç›®å½•ï¼Œè·å– Top N é¢˜ç›®å¹¶æå–å¹³å°åç§°"""
    problems = []
    if not os.path.exists(folder): return []
    for root, _, files in os.walk(folder):
        for f in files:
            if f.endswith('.cpp'):
                path = os.path.join(root, f)
                url = get_oj_url(path)
                if url:
                    # è·å–å¹³å°åç§°
                    rel_root = os.path.relpath(root, folder)
                    platform = rel_root.split(os.sep)[0] if rel_root != "." else "Other"
                    
                    mtime = os.path.getmtime(path)
                    problems.append({
                        'name': f.replace('.cpp', ''),
                        'url': url,
                        'platform': platform,
                        'time': mtime
                    })
    problems.sort(key=lambda x: x['time'], reverse=reverse_sort)
    return problems[:TOP_N]

def update_readme():
    """ç”Ÿæˆçœ‹æ¿ HTML å¹¶æ›´æ–° README"""
    now = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    daily_ac, platforms = get_stats()
    
    recent_ac = get_top_n(ACCEPTED_DIR, reverse_sort=True)
    oldest_pending = get_top_n(ATTEMPTED_DIR, reverse_sort=False)

    # çœ‹æ¿ HTML
    dashboard_html = f"""
<table width="100%">
    <tr>
        <td width="50%" valign="top">
            <h4 align="center">âœ… æœ€è¿‘ AC ({len(recent_ac)})</h4>
            <table width="100%">
                <thead><tr><th align="center">å¹³å°</th><th align="left">é¢˜ç›®</th><th align="right">æ—¥æœŸ</th></tr></thead>
                <tbody>
                {"".join([f"<tr><td align='center'><code>{p['platform']}</code></td><td><a href='{p['url']}'>{p['name']}</a></td><td align='right'>{datetime.fromtimestamp(p['time']).strftime('%m-%d')}</td></tr>" for p in recent_ac]) if recent_ac else "<tr><td colspan='3' align='center'>æš‚æ— è®°å½•</td></tr>"}
                </tbody>
            </table>
        </td>
        <td width="50%" valign="top">
            <h4 align="center">âŒ› ç§¯å‹æœ€ä¹… ({len(oldest_pending)})</h4>
            <table width="100%">
                <thead><tr><th align="center">å¹³å°</th><th align="left">é¢˜ç›®</th><th align="right">æ—¥æœŸ</th></tr></thead>
                <tbody>
                {"".join([f"<tr><td align='center'><code>{p['platform']}</code></td><td><a href='{p['url']}'>{p['name']}</a></td><td align='right'>{datetime.fromtimestamp(p['time']).strftime('%m-%d')}</td></tr>" for p in oldest_pending]) if oldest_pending else "<tr><td colspan='3' align='center'>æš‚æ— ç§¯å‹é¢˜ç›®ï¼Œè¡¥é¢˜æ•ˆç‡æ»¡åˆ†ï¼ï¼</td></tr>"}
                </tbody>
            </table>
        </td>
    </tr>
</table>
"""

    content = [
        "# ğŸ† Algorithm Training Log\n",
        f"> ğŸ¯ **Goal:** ACM Silver Medal | *Last updated: {now}*\n\n",
        "## ğŸ“ˆ Heatmap\n",
        "![Algorithm Training Heatmap](ac_heatmap.png)\n\n",
        "--- \n\n",
        "## ğŸ•’ Dashboard\n",
        dashboard_html + "\n",
        "--- \n\n",
        "## ğŸ“Š AC History\n\n"
    ]

    if daily_ac:
        content.append("| æ—¥æœŸ | " + " | ".join(platforms) + " | **Total** |\n")
        content.append("| :--- | " + " | ".join([":---:"] * len(platforms)) + " | :---: |\n")
        for d in sorted(daily_ac.keys(), reverse=True):
            row = [str(daily_ac[d][p]) if daily_ac[d][p] > 0 else "-" for p in platforms]
            content.append(f"| {d} | " + " | ".join(row) + f" | **{sum(daily_ac[d].values())}** |\n")

    with open(README_FILE, 'w', encoding='utf-8') as f:
        f.writelines(content)
    
    persist_to_csv(daily_ac, platforms)

if __name__ == "__main__":
    update_readme()
    print(f"âœ… README ä¸ CSV æ•°æ®å·²åŒæ­¥ï¼")